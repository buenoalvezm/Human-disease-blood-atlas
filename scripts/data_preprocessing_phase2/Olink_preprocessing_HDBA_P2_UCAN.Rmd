---
title: "Human Disease Blood Atlas Olink Data Quality Control"
subtitle: "Phase 2 (Olink HT) - Batch 1"
author: "María Bueno Álvez"
date: last-modified
date-format: "YYYY-MM-DD"
format:
  html:
    self-contained: true
    theme: flatly
    title-block-banner: true
    smooth-scroll: true
    toc: true
    toc-depth: 4
    toc-location: right
    number-sections: true
    number-depth: 4
    code-fold: true
    code-tools: true
    code-copy: true
    code-overflow: wrap
    df-print: kable
    standalone: false
    fig-align: left
    figure:
      caption: "Figure {number}: {label}"
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
# Load packages
library(tidyverse) 
library(ggplotify)
library(patchwork)
library(pheatmap)
library(ggbeeswarm)
library(ggrepel)
library(GGally)
library(arrow)
library(OlinkAnalyze)

# Read internal functions
source("scripts/functions/functions_utility.R")
source("scripts/functions/functions_visualization.R")
source("scripts/functions/themes_palettes.R")

# Load Olink NPX data and LIMS manifest
data_ht <- read_NPX("data/raw_data/VL-3530B3_NPX_2024-09-25.parquet")
manifest <- import_df("data/samples_2024-04-19.xlsx")
```


```{r, include=FALSE}
# Define control sample type, control assay types, replicate samples, replicate assays
control_sample_types <- c("SAMPLE_CONTROL", "PLATE_CONTROL", "NEGATIVE_CONTROL")

control_assay_types <- c("ext_ctrl", "inc_ctrl", "amp_ctrl")

n_samples_run <- 
  data_ht |> 
  filter(!SampleType %in% control_sample_types) |>
  distinct(SampleID) |> 
  nrow()

replicate_assays <- 
  data_ht |>  
  filter(!SampleType %in% control_sample_types) |>
  group_by(Assay) |> 
  count() |> 
  arrange(-n) |> 
  filter(n > n_samples_run) |> 
  pull(Assay)

control_samples <- 
  manifest |> 
  filter(Cohort == "CTRL") |> 
  pull(DAid)

# Extract Olink assay metadata 
olink_meta <- 
  data_ht |> 
  filter(!AssayType %in% control_assay_types) |>
  distinct(Assay, OlinkID, UniProt, AssayType, Block)

n_proteins <- 
  olink_meta$Assay |>
  unique() |> 
  length()

# Map SampleIDs to DA identifiers 
id_mapping <- 
  data_ht |> 
  filter(SampleType == "SAMPLE") |> 
  distinct(SampleID) |> 
  separate(SampleID, into = c("DAid", "Plate"), sep = "-", remove = F) 

data_hdba <- 
  data_ht |>
  left_join(id_mapping, by = "SampleID") |>
  relocate(DAid)

n_samples <- 
  data_hdba |> 
  filter(!SampleType %in% control_sample_types) |> 
  distinct(DAid) |> 
  nrow()

# Calculate Limit of Detection (LOD) using negative controls
data_ht_lod <- olink_lod(data = data_hdba, lod_method = "NCLOD")

## Save raw data - including LOD calculation
#write_csv(data_ht_lod, file = "../data/final_data/data_phase2_batch1_raw_20241217.csv")  
#write_tsv(data_ht_lod, file = "../data/final_data/data_phase2_batch1_raw_20241217.tsv")  
#write.table(data_ht_lod, file = "../data/final_data/data_phase2_batch1_raw_20241217.txt")  
```


# Data overview

This section provides an **overview of the Olink dataset**, including the total number of samples and proteins measured. 
In the delivered Olink dataset, there are currently **`r n_samples` samples**, and **`r nrow(olink_meta)` proteins** measured in each sample.

**Figure 1**: Number of samples per cohort.

```{r}
data_hdba |> 
  filter(!SampleType %in% control_sample_types) |> 
  distinct(DAid) |> 
  left_join(manifest, by = "DAid") |> 
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
  count(Cohort) |> 
  ggplot(aes(Cohort, n, fill = Cohort)) +
  geom_col() +
  scale_fill_manual(values = pal_phase2) +
  geom_text(aes(label = n), vjust = -0.5) +
  theme_hpa(angled = T) +
  ylab("Number of samples")

#ggsave(savepath("da_phase2_cohorts.png"), h = 6, w = 6)
```

**Figure 2**: Sample distribution across plates.

```{r}
data_hdba |> 
  mutate(Plate = gsub("P", "", Plate),
         Plate = as.numeric(Plate),
         Plate = as.factor(Plate)) |>
  distinct(DAid, SampleID, Plate, SampleType) |> 
  filter(!is.na(Plate)) |> 
  left_join(manifest, by = "DAid") |> 
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_"),
         Cohort = ifelse(SampleType %in% control_sample_types, "CONTROLS", Cohort))  |> 
  group_by(Plate, Cohort) |> 
  count() |> 
  ggplot(aes(Plate, n, fill = Cohort)) +
  geom_col() +
  scale_fill_manual(values = pal_phase2) +
  theme_hpa(angled = T) +
  ylab("Number of samples")

#ggsave(savepath("da_phase2_plates.png"), h = 6, w = 7)
```


# Step 1: Exploration of control samples and control assays

This section identifies and **analyzes control samples to ensure data quality**. Specifically, we explore correlations between technical replicates for selected patients (patient 2 and patient 3) across multiple plates.

## Plate-to-plate correlation for patient 2 & 3

We calculate **Spearman correlations for measurements of Patient 2 and Patient 3 across plates**. These analyses help assess technical reproducibility.



**Figure 3**: Correlation heatmap for Patient 2 across plates.

```{r}
data_ht |> 
  left_join(id_mapping, by = "SampleID") |> 
  filter(DAid == "DA12362") |> 
  select(Plate, OlinkID, PCNormalizedNPX) |> 
  pivot_wider(names_from = OlinkID, values_from = PCNormalizedNPX) |> 
  column_to_rownames("Plate") |> 
  t() |> 
  cor(method = "spearman")|> 
  pheatmap()
```

**Figure 4**: Correlation heatmap for Patient 3 across plates.

```{r}
data_ht |> 
  left_join(id_mapping, by = "SampleID") |> 
  filter(DAid == "DA12363") |> 
  select(Plate, OlinkID, NPX) |> 
  pivot_wider(names_from = OlinkID, values_from = NPX) |> 
  column_to_rownames("Plate") |> 
  t() |> 
  cor(method = "spearman")|> 
  pheatmap() 
```


**Figure 5**: Scatterplots showing pairwise correlations between plates for Patient 2.

```{r warning=FALSE, message=FALSE}
data_ht |> 
  left_join(id_mapping, by = "SampleID") |> 
  filter(DAid == "DA12362") |> 
  select(Plate, OlinkID, NPX) |> 
  pivot_wider(names_from = Plate, values_from = NPX) |> 
  ggpairs(c(2:13),
            lower = list(continuous = "points", size = 0.05)) +
  ggtitle("Correlation for Patient 2 measurements across plates") 

#ggsave(savepath("p2_plate_scatterplots.png"), h = 10, w = 10)
```

**Figure 6**: Scatterplots showing pairwise correlations between plates for Patient 3.

```{r warning=FALSE, message=FALSE}
data_ht |> 
  left_join(id_mapping, by = "SampleID") |> 
  filter(DAid == "DA12363") |> 
  select(Plate, OlinkID, NPX) |> 
  pivot_wider(names_from = Plate, values_from = NPX) |> 
  ggpairs(c(2:13),
            lower = list(continuous = "points", size = 0.5)) +
  ggtitle("Correlation for Patient 3 measurements across plates")

#ggsave(savepath("p3_plate_scatterplots.png"), h = 10, w = 10)
```

### Correlation excluding proteins below LOD

This section refines the **correlation analysis by excluding proteins that fall below the LOD across all replicates**. This step ensures a cleaner analysis focusing only on reliably measured proteins.

```{r warning=FALSE, message=FALSE}
exclude_proteins <- 
  data_ht_lod |> 
  filter(DAid %in% control_samples) |> 
  mutate(under_LOD = ifelse(NPX < LOD, "Yes", "No")) |> 
  group_by(Assay) |> 
  count(under_LOD) |> 
  filter(under_LOD == "Yes") |> 
  ungroup() |> 
  filter(n > length(unique(data_ht$PlateID)))
```

**Figure 7**: Heatmaps of correlations for Patient 2 measurements (filtered for proteins above LOD).

```{r}
data_ht |> 
  left_join(id_mapping, by = "SampleID") |> 
  filter(DAid == "DA12362",
         !Assay %in% exclude_proteins$Assay) |> 
  select(Plate, OlinkID, PCNormalizedNPX) |> 
  pivot_wider(names_from = OlinkID, values_from = PCNormalizedNPX) |> 
  column_to_rownames("Plate") |> 
  t() |> 
  cor(method = "spearman")|> 
  pheatmap() 
```

**Figure 8**: Heatmaps of correlations for Patient 3 measurements (filtered for proteins above LOD).

```{r}
data_ht |> 
  left_join(id_mapping, by = "SampleID") |> 
  filter(DAid == "DA12363",
         !Assay %in% exclude_proteins$Assay) |> 
  select(Plate, OlinkID, NPX) |> 
  pivot_wider(names_from = OlinkID, values_from = NPX) |> 
  column_to_rownames("Plate") |> 
  t() |> 
  cor(method = "spearman")|> 
  pheatmap() 
```



## Remove control assays & samples

In this step, we **filter out control assays and samples** that are not part of the main dataset. This ensures clean data for downstream analyses.

```{r}
data_step_1 <- 
  data_ht_lod |> 
  filter(!SampleType %in% control_sample_types,
         !DAid %in% control_samples, # Remove internal KTH controls
         !AssayType %in% control_assay_types) |>
  select(DAid, Assay, OlinkID, UniProt, Panel, Block, Plate, Count, ExtNPX, NPX, PCNormalizedNPX, AssayQC, SampleQC, LOD) |> 
  mutate(above_LOD = ifelse(NPX > LOD, "Yes", "No"))
```

## Save control data for Olink

Here, we save **control data for internal investigations at Olink**. These control assays and samples are retained separately for quality control and troubleshooting purposes.


```{r}
data_olink_controls <- 
  data_hdba |> 
  filter(SampleType %in% control_sample_types) |> 
  select(-DAid, -Plate)

#write_parquet(data_olink_controls, "data/final_data/Olink/data_phase2_olink_internal_controls_20240916.parquet")  

data_hdba_controls <- 
  data_hdba |> 
  filter(DAid %in% control_samples) |> 
  select(-DAid, -Plate)

#write_parquet(data_hdba_controls, "data/final_data/Olink/data_phase2_kth_internal_controls_20240916.parquet")  
```

# Step 2: QC warnings

In this step, we assess **quality control (QC) warnings at the sample and protein levels**. Samples or protein measurements flagged with warnings will be excluded based on predefined thresholds.

## Percentage of QC warnings per sample
We calculate the number of QC warnings per sample, with a focus on those that do not pass QC.

**Figure 9**: Barplot showing the number of QC warnings for each sample, colored by cohort.

```{r}
data_step_1 |> 
  group_by(DAid) |> 
  count(SampleQC) |> 
  filter(!SampleQC %in% c("NA", "PASS")) |> 
  arrange(-n) |> 
  left_join(manifest, by = "DAid") |> 
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
  ggplot(aes(fct_reorder(DAid, -n), n, fill = Cohort)) +
  geom_col() +
  scale_fill_manual(values = pal_phase2) +
  geom_hline(yintercept = 5440/2, linetype = "dashed", color = "grey") +
  theme_hpa(angled = T) +
  xlab("Sample") +
  # theme(axis.text.x = element_blank(),
  #       axis.ticks = element_blank()) +
  ggtitle("Samples with QC warnings") 


#ggsave(savepath("samples_qc.png"), h = 4, w = 10)
```

**Figure 10**: Beeswarm plot showing the number of proteins passing QC for each sample.

```{r}
data_step_1 |> 
  group_by(DAid) |> 
  filter(SampleQC == "PASS") |>
  count(SampleQC) |> 
  left_join(manifest, by = "DAid") |> 
  filter(Cohort != "CTRL") |> 
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
  ggplot(aes(Cohort, n, color = Cohort)) +
  geom_quasirandom() +
  geom_hline(yintercept = n_proteins / 2, color = "grey40", linetype = "dashed") +
 # geom_text_repel(aes(label = DAid), show.legend = F) +
  scale_color_manual(values = pal_phase2) +
  theme_hpa(angled = T) +
  ggtitle("Number of proteins that pass QC per sample")

#ggsave(savepath("samples_pass.png"), h = 8, w = 8)
```


## Samples with > 50% QC warnings

This analysis identifies samples with more than 50% of proteins flagged with QC warnings, which will be excluded from further analysis.

```{r}
samples_high_warnings <- 
  data_step_1 |> 
  group_by(DAid) |> 
  count(SampleQC) |> 
  filter(SampleQC == "FAIL") |> 
  mutate(perc_warning = n / n_proteins) |> 
  filter(perc_warning > 0.5) 
```

In the current dataset, the **number of samples with > 50% warnings is: `r nrow(samples_high_warnings)`**.

These samples will be excluded from further analysis.

## Remove individual sample QC warnings

In this step, we **filter out the samples identified in the previous step that have more than 50% QC warnings**. Additionally, we **remove protein measurements that failed QC**. Since the data is in long format, this step will not introduce any NAs. However, when the data is reshaped into a wide format, missing values may be introduced.

```{r}
data_step_2 <- 
  data_step_1 |> 
  filter(SampleQC == "PASS",
         !DAid %in% samples_high_warnings$DAid) |>
  select(-SampleQC)
```

# Step 3: Assay warnings

In this step, we evaluate **quality control (QC) warnings at the assay level**. Assays with a high percentage of warnings will be flagged and excluded from the dataset based on a predefined threshold to ensure data reliability.

**Figure 11**: Bar plot showing the number of assays with warnings across different assays.

```{r}
data_step_2 |>
  group_by(Assay) |> 
  count(AssayQC) |> 
  filter(!AssayQC %in% c("NA", "PASS")) |> 
  arrange(-n) |> 
  ggplot(aes(fct_reorder(Assay,-n), n)) +
  geom_col() +
  geom_text(aes(label = n), vjust = -0.5) +
  theme_hpa(angle = T) +
  xlab("Assay")

#ggsave(savepath("assay_qc.png"), h = 5, w = 10)

assays_high_warnings <- 
  data_step_2 |> 
  filter(!DAid %in% control_samples) |> 
  group_by(Assay) |> 
  mutate(n_total = n_distinct(DAid)) |> 
  filter(AssayQC == "WARN") |> 
  mutate(n = n_distinct(DAid)) |> 
  ungroup() |> 
  distinct(Assay, n, n_total) |> 
  mutate(perc_warning = n / n_total) |> arrange(-n) |> 
  filter(perc_warning > 0.5) 
```

In the current dataset, the number of **assays with > 50% warnings is: `r nrow(assays_high_warnings)`**.  

These assays will be excluded from further analysis.

```{r}
data_step_3 <- 
  data_step_2 |> 
  filter(!Assay %in% assays_high_warnings$Assay) |>
  select(-AssayQC)
```

# Step 4: Bridging samples
*This step is not applicable to the preprocessing of batch 1 alone. It will be updated once additional batches are incorporated into the preprocessing pipeline.*

```{r}
data_step_4 <- 
  data_step_3
```


# Step 5: Replicate proteins

In this step, we **assess replicate protein measurements**, where proteins are run multiple times (across different dilution blocks) in the Olink HT platform. We begin by examining the correlation of replicate assays and then select the **assay with the highest fraction of datapoints above the limit of detection (LOD)** for downstream analysis.

## Assay correlations 

**Figure 12**: Scatterplot matrix showing the correlation of replicate protein measurements for GBP1. Each point represents a sample, colored by cohort, with the aim of visualizing the consistency between replicates.

```{r warning=FALSE, message=FALSE}
data_step_4 |> 
  filter(Assay == "GBP1") |> 
  select(OlinkID, NPX, DAid) |> 
  pivot_wider(names_from = OlinkID, values_from = NPX) |> 
  left_join(manifest, by = "DAid") |> 
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
  ggpairs(2:4, title = "GBP1",
          mapping = ggplot2::aes(color = Cohort)) +
  scale_fill_manual(values = pal_phase2) +
  scale_color_manual(values = pal_phase2) +
  theme_hpa() 

#ggsave(savepath("GBP1_replicates.png"), h = 8, w = 8)
```

**Figure 13**: Scatterplot matrix showing the correlation of replicate protein measurements for MAP2K1. Each point represents a sample, colored by cohort, with the aim of visualizing the consistency between replicates.

```{r warning=FALSE, message=FALSE}
data_step_4 |> 
  filter(Assay == "MAP2K1") |> 
  select(OlinkID, NPX, DAid) |> 
  pivot_wider(names_from = OlinkID, values_from = NPX) |> 
  left_join(manifest, by = "DAid") |> 
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
  ggpairs(2:4, title = "MAP2K1",
          mapping = ggplot2::aes(color = Cohort)) +
  scale_fill_manual(values = pal_phase2) +
  scale_color_manual(values = pal_phase2) +
  theme_hpa() 

#ggsave(savepath("MAP2K1_replicates.png"), h = 8, w = 8)
```


## Selection of replicate assay based on LOD

**Figure 14**: Bar plot showing the number of values under the LOD for each replicate assay. 

```{r}
replicate_assays_lod <- 
  data_ht_lod |> 
  filter(Assay %in% replicate_assays) |> 
  mutate(below_LOD = ifelse(NPX < LOD, "Yes", "No")) |> 
  group_by(Assay, OlinkID) |> 
  count(below_LOD, Block) |> 
  filter(below_LOD == "Yes") |>
  group_by(Assay) 

replicate_assays_lod |> 
  ggplot(aes(OlinkID, n, fill = Block)) +
  geom_col() +
  geom_text(aes(label = n), vjust = -0.5) +
  facet_wrap(~Assay, scales = "free") +
  scale_fill_brewer() +
  theme_hpa(angled = T) +
  ggtitle("Values under LOD per assay")

#ggsave(savepath("values_under_lod_replicate_assays.png"), h = 6, w = 7)

replicate_assays_remove <- 
  replicate_assays_lod |> 
  top_n(2, n)

data_step_5 <-
  data_step_4 |> 
  filter(!OlinkID %in% replicate_assays_remove$OlinkID)
```


# Step 6: LOD investigation

In this step, we will **potentially investigate proteins under the limit of detection (LOD) across samples**. We consider potentially removing proteins that are under LOD in all (or most) samples. This decision will be evaluated once the additional batches are incorporated into the analysis. We will also explore the impact of removing assays with high missingness, particularly in machine learning models, to ensure optimal model performance (suggestion from Klev).

# Step 7: Outlier exploration

In this step, we use **PCA and UAMP to explore potential outliers in the dataset**. By visualizing the data in lower dimensions, we can identify samples that may behave differently from the rest and may need further investigation or exclusion.


```{r}
# Prepare data
input_data <- 
  data_step_5 |>
  select(DAid, OlinkID, NPX) |>
  pivot_wider(names_from = "OlinkID", values_from = "NPX")

exclude_proteins <- 
  data_ht_lod |> 
  filter(DAid %in% control_samples) |> 
  mutate(under_LOD = ifelse(NPX < LOD, "Yes", "No")) |>
  group_by(Assay) |> 
  count(under_LOD) |> 
  filter(under_LOD == "Yes") |> 
  ungroup() |> 
  filter(n >= (length(unique(data_ht$PlateID))*2))

input_data_filt <- 
  data_step_5 |>
  filter(!Assay %in% exclude_proteins$Assay) |> 
  select(DAid, OlinkID, NPX) |>
  pivot_wider(names_from = "OlinkID", values_from = "NPX")
```


## PCA


**Figure 15**: PCA visualization based on all proteins, where samples are colored by cohort.

```{r}
pca_all_proteins <-
  do_pca(data = input_data,
          plots = F)

pca_all_proteins$pca_res |>
  rename(DAid = Sample) |>
  left_join(manifest, by = "DAid") |>
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
  ggplot(aes(PC1, PC2, color = Cohort)) +
  geom_point(alpha = 0.7, size = 0.8) +
  scale_color_manual(values = pal_phase2) +
  theme_hpa() +
  ggtitle("All proteins")
```

**Figure 16**: PCA visualization based on proteins with high detectability, where samples are colored by cohort.

```{r}
# pca_high_detectability <-
#   do_pca(data = input_data_filt,
#          plots = F)
# 
# pca_high_detectability$pca_res |>
#   rename(DAid = Sample) |>
#   left_join(manifest, by = "DAid") |>
#   mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
#   ggplot(aes(PC1, PC2, color = Cohort)) +
#   geom_point(alpha = 0.7, size = 0.8) +
#   scale_color_manual(values = pal_phase2) +
#   theme_hpa() +
#   ggtitle("Proteins with high detectability")
```

We identify the PCA outliers and remove them from the dataset.

```{r}
pca_outliers <-
  pca_all_proteins$pca_res |>
  filter(PC2 > 70) |>
  distinct(Sample)

data_step_6 <-
  data_step_5 |>
  filter(!DAid %in% pca_outliers$Sample)
```

## UMAP

**Figure 17**: UMAP visualization based on all proteins, where samples are colored by cohort.

```{r}
umap_all_proteins <-
  do_umap(data = input_data,
          plots = F)

umap_all_proteins |>
  rename(DAid = Sample) |>
  left_join(manifest, by = "DAid") |>
  mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
  ggplot(aes(UMAP1, UMAP2, color = Cohort)) +
  geom_point(alpha = 0.7, size = 0.8) +
  scale_color_manual(values = pal_phase2) +
  theme_hpa() +
  ggtitle("All proteins")

umap_all_proteins |> 
  filter(UMAP2 < -4)
```

**Figure 18**: UMAP visualization based on proteins with high detectability, where samples are colored by cohort.

```{r}
# umap_high_detectability <-
#   do_umap(data = input_data_filt,
#           plots = F)
# 
# umap_high_detectability |>
#   rename(DAid = Sample) |>
#   left_join(manifest, by = "DAid") |>
#   mutate(Cohort = paste(Cohort, `PI - sample owner`, sep = "_")) |>
#   ggplot(aes(UMAP1, UMAP2, color = Cohort)) +
#   geom_point(alpha = 0.7, size = 0.8) +
#   scale_color_manual(values = pal_phase2) +
#   theme_hpa() +
#   ggtitle("Proteins with high detectability")
```


# Save final data

After completing the quality control and data curation steps, we **save the cleaned and processed dataset for sharing with collaborators and for further downstream analysis**. This final dataset is ready for use in subsequent phases of the project.

```{r}
write_tsv(data_step_6, file = "data/final_data/data_phase2_batch3_curated_20250127.tsv") 
```

